<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/algorithms/ball_prune.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/algorithms/ball_prune.py" />
              <option name="originalContent" value="# algorithms/ball_prune.py&#10;# Адаптер вокруг реализаций из allens_code (Ball-Prune / dynamic radius BFS)&#10;import time&#10;import os&#10;from typing import Tuple&#10;import numpy as np&#10;import psutil&#10;&#10;# Импортируем функции из allens_code&#10;from allens_code.functions.construction import (&#10;    build_ball_traversable_graph,&#10;    create_percentile_radii_by_node,&#10;)&#10;from allens_code.functions.query import bfs_within_ball_dynamic&#10;from allens_code.functions.distance import sq_Euclidean_d&#10;&#10;&#10;class Algo:&#10;    def __init__(self, metric: str = &quot;l2&quot;, use_empirical=False, hnsw_M: int = 32, ef_search: int = 1,&#10;                 seed_select_sample: int = 256):&#10;        if metric != &quot;l2&quot;:&#10;            raise ValueError(&quot;Ball_Prune поддерживает только metric='l2' на текущем этапе&quot;)&#10;        self.metric = metric&#10;        self.use_empirical = use_empirical&#10;        self.hnsw_M = hnsw_M&#10;        self.ef_search = ef_search&#10;        self.seed_select_sample = seed_select_sample&#10;&#10;        self.xb: np.ndarray | None = None&#10;        self.graph = None&#10;        self.safe_radii_by_node = None&#10;        self.percentile_radii_by_node = None&#10;&#10;        self._stats = {&#10;            &quot;build_time_s&quot;: None,&#10;            &quot;ram_rss_mb_after_build&quot;: None,&#10;            &quot;edges&quot;: None,&#10;        }&#10;&#10;    def build(self, xb: np.ndarray, metric: str | None = None):&#10;        if metric is not None and metric != self.metric:&#10;            if metric != &quot;l2&quot;:&#10;                raise ValueError(&quot;Ball_Prune поддерживает только metric='l2'&quot;)&#10;        t0 = time.perf_counter()&#10;&#10;        self.xb = xb.astype(np.float32, copy=False)&#10;&#10;        # Строим направленный граф и уровни безопасных радиусов&#10;        self.graph, self.safe_radii_by_node = build_ball_traversable_graph(self.xb)&#10;&#10;        # Необязательная эмпирическая подстройка радиусов (дорого, выключено по умолчанию)&#10;        if self.use_empirical:&#10;            # По умолчанию k=5, p=0.95 как в исходнике; можно настроить через конструктор при необходимости&#10;            self.percentile_radii_by_node = create_percentile_radii_by_node(self.xb, self.safe_radii_by_node, k=5, p=0.95)&#10;        else:&#10;            self.percentile_radii_by_node = None&#10;&#10;        build_time_s = time.perf_counter() - t0&#10;        self._stats[&quot;build_time_s&quot;] = float(build_time_s)&#10;        self._stats[&quot;ram_rss_mb_after_build&quot;] = psutil.Process(os.getpid()).memory_info().rss / 1e6&#10;        # число рёбер&#10;        if self.graph is not None:&#10;            self._stats[&quot;edges&quot;] = int(sum(len(v) for v in self.graph.values()))&#10;        else:&#10;            self._stats[&quot;edges&quot;] = 0&#10;&#10;    def _choose_seed(self, q: np.ndarray) -&gt; int:&#10;        &quot;&quot;&quot;Простой выбор стартовой точки: перебираем небольшой семпл базы и берём ближайшую по L2.&quot;&quot;&quot;&#10;        n = self.xb.shape[0]&#10;        if n &lt;= self.seed_select_sample:&#10;            cand = np.arange(n)&#10;        else:&#10;            # фиксированная подвыборка для скорости&#10;            rng = np.random.default_rng(12345)&#10;            cand = rng.choice(n, size=self.seed_select_sample, replace=False)&#10;        # считаем квадрат L2 до кандидатов&#10;        d2 = np.sum((self.xb[cand] - q) ** 2, axis=1)&#10;        return int(cand[int(np.argmin(d2))])&#10;&#10;    def _query_one(self, q: np.ndarray, k: int) -&gt; Tuple[np.ndarray, np.ndarray]:&#10;        q = q.astype(np.float32, copy=False)&#10;        root = self._choose_seed(q)&#10;        expanded, knn_list, _jumps = bfs_within_ball_dynamic(&#10;            graph=self.graph,&#10;            dataset=self.xb,&#10;            root=root,&#10;            k=k,&#10;            query=q,&#10;            evaluated_set=set(),&#10;            traversable_radii_by_node=self.safe_radii_by_node,&#10;            percentile_radii_by_node=self.percentile_radii_by_node,&#10;        )&#10;        # knn_list: list[(dist, idx)] по возрастанию dist&#10;        if len(knn_list) == 0:&#10;            # fallback: если ничего не найдено (маловероятно), вернём ближайшее из семпла&#10;            root = self._choose_seed(q)&#10;            d = sq_Euclidean_d(q, self.xb[root])&#10;            return np.array([root], dtype=np.int64), np.array([d], dtype=np.float32)&#10;        idx = np.array([i for _, i in knn_list[:k]], dtype=np.int64)&#10;        dist = np.array([d for d, _ in knn_list[:k]], dtype=np.float32)&#10;        return idx, dist&#10;&#10;    def query(self, xq: np.ndarray, k: int):&#10;        if self.xb is None or self.graph is None:&#10;            raise RuntimeError(&quot;Index not built. Call build() first.&quot;)&#10;        xq = xq.astype(np.float32, copy=False)&#10;        nq = xq.shape[0]&#10;        I = np.empty((nq, k), dtype=np.int64)&#10;        D = np.empty((nq, k), dtype=np.float32)&#10;        for i in range(nq):&#10;            idx, dist = self._query_one(xq[i], k)&#10;            if idx.shape[0] &lt; k:&#10;                # добьём до k простым брутфорсом по базе — редкий случай&#10;                need = k - idx.shape[0]&#10;                # посчитаем до небольшого семпла оставшиеся&#10;                n = self.xb.shape[0]&#10;                rest = np.setdiff1d(np.arange(n, dtype=np.int64), idx, assume_unique=False)&#10;                if rest.size &gt; 0:&#10;                    cand = rest if rest.size &lt;= 1024 else rest[:1024]&#10;                    scores = np.sum((self.xb[cand] - xq[i]) ** 2, axis=1)&#10;                    ord_ = np.argsort(scores)[:need]&#10;                    idx = np.concatenate([idx, cand[ord_]])&#10;                    dist = np.concatenate([dist, scores[ord_].astype(np.float32)])&#10;            I[i, :k] = idx[:k]&#10;            D[i, :k] = dist[:k]&#10;        return I, D&#10;&#10;    def stats(self):&#10;        return dict(self._stats)&#10;&#10;" />
              <option name="updatedContent" value="# algorithms/ball_prune.py&#10;# Адаптер вокруг реализаций из allens_code (Ball-Prune / dynamic radius BFS)&#10;import time&#10;from typing import Tuple, Optional, Dict, Any&#10;import numpy as np&#10;import psutil&#10;&#10;# Импортируем функции из allens_code&#10;from allens_code.functions.construction import (&#10;    build_ball_traversable_graph,&#10;    create_percentile_radii_by_node,&#10;)&#10;from allens_code.functions.query import bfs_within_ball_dynamic&#10;from allens_code.functions.distance import sq_Euclidean_d&#10;&#10;&#10;class Algo:&#10;    def __init__(self, metric: str = &quot;l2&quot;, use_empirical=False, hnsw_M: int = 32, ef_search: int = 1,&#10;                 seed_select_sample: int = 256):&#10;        if metric != &quot;l2&quot;:&#10;            raise ValueError(&quot;Ball_Prune поддерживает только metric='l2' на текущем этапе&quot;)&#10;        self.metric = metric&#10;        self.use_empirical = use_empirical&#10;        self.hnsw_M = hnsw_M&#10;        self.ef_search = ef_search&#10;        self.seed_select_sample = seed_select_sample&#10;&#10;        self.xb: Optional[np.ndarray] = None&#10;        self.graph = None&#10;        self.safe_radii_by_node = None&#10;        self.percentile_radii_by_node = None&#10;&#10;        self._stats: Dict[str, Any] = {&#10;            &quot;build_time_s&quot;: None,&#10;            &quot;ram_rss_mb_after_build&quot;: None,&#10;            &quot;edges&quot;: None,&#10;        }&#10;&#10;    def build(self, xb: np.ndarray, metric: Optional[str] = None):&#10;        if metric is not None and metric != self.metric:&#10;            if metric != &quot;l2&quot;:&#10;                raise ValueError(&quot;Ball_Prune поддерживает только metric='l2'&quot;)&#10;        t0 = time.perf_counter()&#10;&#10;        self.xb = xb.astype(np.float32, copy=False)&#10;&#10;        # Строим направленный граф и уровни безопасных радиусов&#10;        self.graph, self.safe_radii_by_node = build_ball_traversable_graph(self.xb)&#10;&#10;        # Необязательная эмпирическая подстройка радиусов (дорого, выключено по умолчанию)&#10;        if self.use_empirical:&#10;            # По умолчанию k=5, p=0.95 как в исходнике; можно настроить через конструктор при необходимости&#10;            self.percentile_radii_by_node = create_percentile_radii_by_node(self.xb, self.safe_radii_by_node, k=5, p=0.95)&#10;        else:&#10;            self.percentile_radii_by_node = None&#10;&#10;        build_time_s = time.perf_counter() - t0&#10;        self._stats[&quot;build_time_s&quot;] = float(build_time_s)&#10;        self._stats[&quot;ram_rss_mb_after_build&quot;] = psutil.Process().memory_info().rss / 1e6&#10;        # число рёбер&#10;        if self.graph is not None:&#10;            self._stats[&quot;edges&quot;] = int(sum(len(v) for v in self.graph.values()))&#10;        else:&#10;            self._stats[&quot;edges&quot;] = 0&#10;&#10;    def _choose_seed(self, q: np.ndarray) -&gt; int:&#10;        &quot;&quot;&quot;Простой выбор стартовой точки: перебираем небольшой семпл базы и берём ближайшую по L2.&quot;&quot;&quot;&#10;        n = self.xb.shape[0]&#10;        if n &lt;= self.seed_select_sample:&#10;            cand = np.arange(n)&#10;        else:&#10;            # фиксированная подвыборка для скорости&#10;            rng = np.random.default_rng(12345)&#10;            cand = rng.choice(n, size=self.seed_select_sample, replace=False)&#10;        # считаем квадрат L2 до кандидатов&#10;        d2 = np.sum((self.xb[cand] - q) ** 2, axis=1)&#10;        return int(cand[int(np.argmin(d2))])&#10;&#10;    def _query_one(self, q: np.ndarray, k: int) -&gt; Tuple[np.ndarray, np.ndarray]:&#10;        q = q.astype(np.float32, copy=False)&#10;        root = self._choose_seed(q)&#10;        _expanded, knn_list, _jumps = bfs_within_ball_dynamic(&#10;            graph=self.graph,&#10;            dataset=self.xb,&#10;            root=root,&#10;            k=k,&#10;            query=q,&#10;            evaluated_set=set(),&#10;            traversable_radii_by_node=self.safe_radii_by_node,&#10;            percentile_radii_by_node=self.percentile_radii_by_node,&#10;        )&#10;        # knn_list: list[(dist, idx)] по возрастанию dist&#10;        if len(knn_list) == 0:&#10;            # fallback: если ничего не найдено (маловероятно), вернём ближайшее из семпла&#10;            root = self._choose_seed(q)&#10;            d = sq_Euclidean_d(q, self.xb[root])&#10;            return np.array([root], dtype=np.int64), np.array([d], dtype=np.float32)&#10;        idx = np.array([i for d, i in knn_list[:k]], dtype=np.int64)&#10;        dist = np.array([d for d, i in knn_list[:k]], dtype=np.float32)&#10;        return idx, dist&#10;&#10;    def query(self, xq: np.ndarray, k: int):&#10;        if self.xb is None or self.graph is None:&#10;            raise RuntimeError(&quot;Index not built. Call build() first.&quot;)&#10;        xq = xq.astype(np.float32, copy=False)&#10;        nq = xq.shape[0]&#10;        I = np.empty((nq, k), dtype=np.int64)&#10;        D = np.empty((nq, k), dtype=np.float32)&#10;        for i in range(nq):&#10;            idx, dist = self._query_one(xq[i], k)&#10;            if idx.shape[0] &lt; k:&#10;                # добьём до k простым брутфорсом по базе — редкий случай&#10;                need = k - idx.shape[0]&#10;                # посчитаем до небольшого семпла оставшиеся&#10;                n = self.xb.shape[0]&#10;                rest = np.setdiff1d(np.arange(n, dtype=np.int64), idx, assume_unique=False)&#10;                if rest.size &gt; 0:&#10;                    cand = rest if rest.size &lt;= 1024 else rest[:1024]&#10;                    scores = np.sum((self.xb[cand] - xq[i]) ** 2, axis=1)&#10;                    ord_ = np.argsort(scores)[:need]&#10;                    idx = np.concatenate([idx, cand[ord_]])&#10;                    dist = np.concatenate([dist, scores[ord_].astype(np.float32)])&#10;            I[i, :k] = idx[:k]&#10;            D[i, :k] = dist[:k]&#10;        return I, D&#10;&#10;    def stats(self):&#10;        return dict(self._stats)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/allens_code/functions/construction.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/allens_code/functions/construction.py" />
              <option name="originalContent" value="import numpy as np&#10;from collections import deque, defaultdict&#10;import faiss&#10;from Exact_efSearch_functions.distance import sq_Euclidean_d&#10;&#10;def bfs_within_ball(graph, dataset, root, radius):&#10;    &quot;&quot;&quot;Returns all nodes reachable from `root` within `radius` using outgoing edges.&quot;&quot;&quot;&#10;    visited = set()&#10;    queue = deque([root])&#10;    visited.add(root)&#10;    center = dataset[root]&#10;&#10;    while queue:&#10;        node = queue.popleft()&#10;        for neighbor in graph[node]:&#10;            if neighbor in visited:&#10;                continue&#10;            if sq_Euclidean_d(dataset[neighbor],center) &lt;= radius:&#10;                visited.add(neighbor)&#10;                queue.append(neighbor)&#10;    return visited&#10;&#10;def build_ball_traversable_graph(dataset):&#10;    &quot;&quot;&quot;&#10;    Construct a directed graph such that for every node v and each radius corresponding&#10;    to the 1, 2, 4, 8, ..., max_neighbors-th closest neighbors (including the furthest one),&#10;    the subgraph induced by B_r(v) is traversable from v.&#10;&#10;    Args:&#10;        dataset: np.ndarray of shape (n, d)&#10;        max_neighbors: int — maximum number of neighbors to consider (default: all)&#10;&#10;    Returns:&#10;        graph: dict[int, List[int]] — directed adjacency list&#10;        straversable_radii_by_node: dict[int, List[float]] — guaranteed traversable radii per node&#10;    &quot;&quot;&quot;&#10;    n = len(dataset)&#10;    graph = defaultdict(list)&#10;    traversable_radii_by_node = {}&#10;&#10;    for v in range(n):&#10;        # Compute and sort distances from v to all other nodes&#10;        dists = [(u, sq_Euclidean_d(dataset[v],dataset[u])) for u in range(n) if u != v]&#10;        dists.sort(key=lambda x: x[1])&#10;&#10;        # Select geometric progression indices&#10;        traversable_indices = [0]&#10;        i = 1&#10;        while i &lt;= len(dists):&#10;            traversable_indices.append(i)&#10;            i *= 2&#10;&#10;        # Ensure the final index is included&#10;        if len(dists) not in traversable_indices:&#10;            traversable_indices.append(len(dists))&#10;&#10;        # Process each safe radius&#10;        traversable_radii = []&#10;        for idx in traversable_indices:&#10;            u_subset = dists[:idx + 1]&#10;            max_r = u_subset[-1][1]&#10;            traversable_radii.append((idx, max_r))&#10;&#10;            reachable = bfs_within_ball(graph, dataset, v, max_r)&#10;&#10;            for u, dist in u_subset:&#10;                if u in reachable:&#10;                    continue&#10;                if not reachable:&#10;                    graph[v].append(u)&#10;                else:&#10;                    closest = min(&#10;                        reachable,&#10;                        key=lambda w: sq_Euclidean_d(dataset[u],dataset[w])&#10;                    )&#10;                    graph[closest].append(u)&#10;&#10;                # Update reachability after each new edge&#10;                reachable = bfs_within_ball(graph, dataset, v, max_r)&#10;&#10;        traversable_radii_by_node[v] = traversable_radii&#10;&#10;    return graph, traversable_radii_by_node&#10;&#10;def compute_exact_knns(dataset, k):&#10;    &quot;&quot;&quot;&#10;    Compute the exact kNNs for each point in the dataset using brute-force search.&#10;&#10;    Args:&#10;        dataset: np.ndarray of shape (n, d)&#10;        k: int — number of nearest neighbors&#10;&#10;    Returns:&#10;        knns_by_node: dict[int, List[Tuple[int, float]]]&#10;                      Maps each node index to list of (neighbor index, distance)&#10;    &quot;&quot;&quot;&#10;    n = len(dataset)&#10;    knns_by_node = defaultdict(list)&#10;&#10;    for i in range(n):&#10;        dists = [(j, sq_Euclidean_d(dataset[i],dataset[j])) for j in range(n) if j != i]&#10;        dists.sort(key=lambda x: x[1])&#10;        knns_by_node[i] = dists[:k]&#10;&#10;    return knns_by_node&#10;&#10;def compute_empirical_geometry(dataset, traversable_radii_by_node, knns_by_node):&#10;    &quot;&quot;&quot;&#10;    For each node v and each traversable radius idx (corresponding to a ball radius centered at v),&#10;    determine the empirical radius needed to cover the kNNs of the boundary node u = u_subset[-1][0],&#10;    and record the rank of the furthest of those neighbors from v.&#10;&#10;    Returns:&#10;        empirical_geometry: dict[int, dict[int, dict[str, float or int]]]&#10;            Structure:&#10;            empirical_geometry[v][idx] = {&#10;                &quot;radius&quot;: float,   # max distance from v to any of u's kNNs&#10;                &quot;rank&quot;: int        # rank of the furthest such kNN in v's distance order&#10;            }&#10;    &quot;&quot;&quot;&#10;    n = len(dataset)&#10;    empirical_geometry = defaultdict(dict)&#10;&#10;    for v in range(n):&#10;        # Precompute all distances from v to others&#10;        dists_v = [(j, sq_Euclidean_d(dataset[v],dataset[j])) for j in range(n) if j != v]&#10;        dists_v.sort(key=lambda x: x[1])&#10;        sorted_indices = [j for j, _ in dists_v]&#10;&#10;        for idx, r in traversable_radii_by_node[v]:&#10;            if idx &gt;= len(dists_v):&#10;                continue&#10;            u = sorted_indices[idx]&#10;&#10;            knns_u = [j for j, _ in knns_by_node[u]]&#10;            dists_to_v = [(j, sq_Euclidean_d(dataset[v],dataset[j])) for j in knns_u]&#10;            dists_to_v.sort(key=lambda x: x[1])&#10;&#10;            furthest_idx, furthest_dist = dists_to_v[-1]&#10;            try:&#10;                rank = sorted_indices.index(furthest_idx)&#10;            except ValueError:&#10;                rank = -1  # Should not happen if dataset is consistent&#10;&#10;            empirical_geometry[v][idx] = {&#10;                &quot;radius&quot;: furthest_dist, #distance between v and furthest KNN of u&#10;                &quot;index&quot;: furthest_idx, #index of furthest kNN of u&#10;                &quot;rank&quot;: rank #rank of u according to distance from v&#10;            }&#10;&#10;    return empirical_geometry&#10;&#10;def compute_percentile_ranks(empirical_geometry, p):&#10;    &quot;&quot;&quot;&#10;    For each traversable index (idx), compute the rank that is greater than or equal to &#10;    p-percent of the recorded ranks across all nodes.&#10;&#10;    Args:&#10;        empirical_geometry: dict[int, dict[int, dict[str, float or int]]]&#10;            Structure: empirical_geometry[v][idx][&quot;rank&quot;]&#10;        p: float in (0, 1), the desired percentile (e.g., 0.9 for 90%)&#10;&#10;    Returns:&#10;        percentile_rank_by_idx: dict[int, int]&#10;            For each idx, the rank such that p% of the entries are ≤ that value.&#10;    &quot;&quot;&quot;&#10;&#10;    rank_lists = defaultdict(list)&#10;&#10;    # Collect all ranks by traversable index&#10;    for v in empirical_geometry:&#10;        for idx in empirical_geometry[v]:&#10;            rank = empirical_geometry[v][idx][&quot;rank&quot;]&#10;            if rank &gt;= 0:&#10;                rank_lists[idx].append(rank)&#10;&#10;    # Compute the percentile rank per index&#10;    percentile_rank_by_idx = {}&#10;    for idx, ranks in rank_lists.items():&#10;        if ranks:&#10;            rank_threshold = int(np.percentile(ranks, 100 * p, interpolation='higher'))&#10;            percentile_rank_by_idx[idx] = rank_threshold&#10;        else:&#10;            percentile_rank_by_idx[idx] = -1  # or np.inf / None if you prefer&#10;&#10;    return percentile_rank_by_idx&#10;&#10;def compute_percentile_radius_by_node(dataset, percentile_ranks):&#10;    &quot;&quot;&quot;&#10;    For each node v and each traversable index, return the distance from v to its&#10;    percentile-determined rank-th nearest neighbor.&#10;&#10;    Args:&#10;        dataset: np.ndarray of shape (n, d)&#10;        percentile_ranks: dict[int, int] — for each traversable index, the desired rank&#10;&#10;    Returns:&#10;        percentile_radii_by_node: dict[int, dict[int, float]]&#10;            Maps each node v to a dictionary mapping traversable idx → distance to rank-th NN&#10;    &quot;&quot;&quot;&#10;    n = len(dataset)&#10;    percentile_radii_by_node = defaultdict(dict)&#10;&#10;    for v in range(n):&#10;        # Precompute distances from v to all others, sorted&#10;        dists = [&#10;            (u, sq_Euclidean_d(dataset[v],dataset[u]))&#10;            for u in range(n) if u != v&#10;        ]&#10;        dists.sort(key=lambda x: x[1])&#10;        dist_list = [dist for _, dist in dists]&#10;&#10;        for idx, rank in percentile_ranks.items():&#10;            if rank &lt; len(dist_list):&#10;                percentile_radii_by_node[v][idx] = dist_list[rank]&#10;            else:&#10;                percentile_radii_by_node[v][idx] = float('inf')  # or np.nan&#10;&#10;    return percentile_radii_by_node&#10;&#10;def construction_phase(dataset, empirical=False, hnsw_M=32, ef_search=1):&#10;    &quot;&quot;&quot;&#10;    Constructs FAISS HNSW graph and ball-traversable graph.&#10;&#10;    Args:&#10;        dataset: np.ndarray of shape (n, d)&#10;        hnsw_M: int, max connections per node for HNSW&#10;        ef_search: int, efSearch parameter during query&#10;&#10;    Returns:&#10;        index: FAISS HNSW index&#10;        graph: dict[int, List[int]], ball-traversable graph&#10;        traversable_radii_by_node: dict[int, List[float]], radius levels used during construction&#10;    &quot;&quot;&quot;&#10;    d = dataset.shape[1]&#10;&#10;    # Build FAISS HNSW index&#10;    index = faiss.IndexHNSWFlat(d, hnsw_M)&#10;    index.hnsw.efSearch = ef_search&#10;    index.hnsw.efConstruction = 100&#10;    index.add(dataset)&#10;&#10;    # Construct ball-traversable graph&#10;    graph, traversable_radii_by_node = build_ball_traversable_graph(dataset)&#10;&#10;    return index, graph, traversable_radii_by_node&#10;&#10;def create_percentile_radii_by_node(dataset, traversable_radii_by_node, k=5, p=0.95):&#10;    knns_by_node = compute_exact_knns(dataset, k=k)&#10;    empirical_geometry = compute_empirical_geometry(dataset, traversable_radii_by_node, knns_by_node)&#10;    percentile_ranks = compute_percentile_ranks(empirical_geometry, p=p)&#10;    percentile_radii_by_node = compute_percentile_radius_by_node(dataset, percentile_ranks)&#10;    return percentile_radii_by_node&#10;&#10;" />
              <option name="updatedContent" value="import numpy as np&#10;from collections import deque, defaultdict&#10;from .distance import sq_Euclidean_d&#10;&#10;def bfs_within_ball(graph, dataset, root, radius):&#10;    &quot;&quot;&quot;Returns all nodes reachable from `root` within `radius` using outgoing edges.&quot;&quot;&quot;&#10;    visited = set()&#10;    queue = deque([root])&#10;    visited.add(root)&#10;    center = dataset[root]&#10;&#10;    while queue:&#10;        node = queue.popleft()&#10;        for neighbor in graph[node]:&#10;            if neighbor in visited:&#10;                continue&#10;            if sq_Euclidean_d(dataset[neighbor],center) &lt;= radius:&#10;                visited.add(neighbor)&#10;                queue.append(neighbor)&#10;    return visited&#10;&#10;def build_ball_traversable_graph(dataset):&#10;    &quot;&quot;&quot;&#10;    Construct a directed graph such that for every node v and each radius corresponding&#10;    to the 1, 2, 4, 8, ..., max_neighbors-th closest neighbors (including the furthest one),&#10;    the subgraph induced by B_r(v) is traversable from v.&#10;&#10;    Args:&#10;        dataset: np.ndarray of shape (n, d)&#10;        max_neighbors: int — maximum number of neighbors to consider (default: all)&#10;&#10;    Returns:&#10;        graph: dict[int, List[int]] — directed adjacency list&#10;        straversable_radii_by_node: dict[int, List[float]] — guaranteed traversable radii per node&#10;    &quot;&quot;&quot;&#10;    n = len(dataset)&#10;    graph = defaultdict(list)&#10;    traversable_radii_by_node = {}&#10;&#10;    for v in range(n):&#10;        # Compute and sort distances from v to all other nodes&#10;        dists = [(u, sq_Euclidean_d(dataset[v],dataset[u])) for u in range(n) if u != v]&#10;        dists.sort(key=lambda x: x[1])&#10;&#10;        # Select geometric progression indices&#10;        traversable_indices = [0]&#10;        i = 1&#10;        while i &lt;= len(dists):&#10;            traversable_indices.append(i)&#10;            i *= 2&#10;&#10;        # Ensure the final index is included&#10;        if len(dists) not in traversable_indices:&#10;            traversable_indices.append(len(dists))&#10;&#10;        # Process each safe radius&#10;        traversable_radii = []&#10;        for idx in traversable_indices:&#10;            u_subset = dists[:idx + 1]&#10;            max_r = u_subset[-1][1]&#10;            traversable_radii.append((idx, max_r))&#10;&#10;            reachable = bfs_within_ball(graph, dataset, v, max_r)&#10;&#10;            for u, dist in u_subset:&#10;                if u in reachable:&#10;                    continue&#10;                if not reachable:&#10;                    graph[v].append(u)&#10;                else:&#10;                    closest = min(&#10;                        reachable,&#10;                        key=lambda w: sq_Euclidean_d(dataset[u],dataset[w])&#10;                    )&#10;                    graph[closest].append(u)&#10;&#10;                # Update reachability after each new edge&#10;                reachable = bfs_within_ball(graph, dataset, v, max_r)&#10;&#10;        traversable_radii_by_node[v] = traversable_radii&#10;&#10;    return graph, traversable_radii_by_node&#10;&#10;def compute_exact_knns(dataset, k):&#10;    &quot;&quot;&quot;&#10;    Compute the exact kNNs for each point in the dataset using brute-force search.&#10;&#10;    Args:&#10;        dataset: np.ndarray of shape (n, d)&#10;        k: int — number of nearest neighbors&#10;&#10;    Returns:&#10;        knns_by_node: dict[int, List[Tuple[int, float]]]&#10;                      Maps each node index to list of (neighbor index, distance)&#10;    &quot;&quot;&quot;&#10;    n = len(dataset)&#10;    knns_by_node = defaultdict(list)&#10;&#10;    for i in range(n):&#10;        dists = [(j, sq_Euclidean_d(dataset[i],dataset[j])) for j in range(n) if j != i]&#10;        dists.sort(key=lambda x: x[1])&#10;        knns_by_node[i] = dists[:k]&#10;&#10;    return knns_by_node&#10;&#10;def compute_empirical_geometry(dataset, traversable_radii_by_node, knns_by_node):&#10;    &quot;&quot;&quot;&#10;    For each node v and each traversable radius idx (corresponding to a ball radius centered at v),&#10;    determine the empirical radius needed to cover the kNNs of the boundary node u = u_subset[-1][0],&#10;    and record the rank of the furthest of those neighbors from v.&#10;&#10;    Returns:&#10;        empirical_geometry: dict[int, dict[int, dict[str, float or int]]]&#10;            Structure:&#10;            empirical_geometry[v][idx] = {&#10;                &quot;radius&quot;: float,   # max distance from v to any of u's kNNs&#10;                &quot;rank&quot;: int        # rank of the furthest such kNN in v's distance order&#10;            }&#10;    &quot;&quot;&quot;&#10;    n = len(dataset)&#10;    empirical_geometry = defaultdict(dict)&#10;&#10;    for v in range(n):&#10;        # Precompute all distances from v to others&#10;        dists_v = [(j, sq_Euclidean_d(dataset[v],dataset[j])) for j in range(n) if j != v]&#10;        dists_v.sort(key=lambda x: x[1])&#10;        sorted_indices = [j for j, _ in dists_v]&#10;&#10;        for idx, r in traversable_radii_by_node[v]:&#10;            if idx &gt;= len(dists_v):&#10;                continue&#10;            u = sorted_indices[idx]&#10;&#10;            knns_u = [j for j, _ in knns_by_node[u]]&#10;            dists_to_v = [(j, sq_Euclidean_d(dataset[v],dataset[j])) for j in knns_u]&#10;            dists_to_v.sort(key=lambda x: x[1])&#10;&#10;            furthest_idx, furthest_dist = dists_to_v[-1]&#10;            try:&#10;                rank = sorted_indices.index(furthest_idx)&#10;            except ValueError:&#10;                rank = -1  # Should not happen if dataset is consistent&#10;&#10;            empirical_geometry[v][idx] = {&#10;                &quot;radius&quot;: furthest_dist, #distance between v and furthest KNN of u&#10;                &quot;index&quot;: furthest_idx, #index of furthest kNN of u&#10;                &quot;rank&quot;: rank #rank of u according to distance from v&#10;            }&#10;&#10;    return empirical_geometry&#10;&#10;def compute_percentile_ranks(empirical_geometry, p):&#10;    &quot;&quot;&quot;&#10;    For each traversable index (idx), compute the rank that is greater than or equal to &#10;    p-percent of the recorded ranks across all nodes.&#10;&#10;    Args:&#10;        empirical_geometry: dict[int, dict[int, dict[str, float or int]]]&#10;            Structure: empirical_geometry[v][idx][&quot;rank&quot;]&#10;        p: float in (0, 1), the desired percentile (e.g., 0.9 for 90%)&#10;&#10;    Returns:&#10;        percentile_rank_by_idx: dict[int, int]&#10;            For each idx, the rank such that p% of the entries are ≤ that value.&#10;    &quot;&quot;&quot;&#10;&#10;    rank_lists = defaultdict(list)&#10;&#10;    # Collect all ranks by traversable index&#10;    for v in empirical_geometry:&#10;        for idx in empirical_geometry[v]:&#10;            rank = empirical_geometry[v][idx][&quot;rank&quot;]&#10;            if rank &gt;= 0:&#10;                rank_lists[idx].append(rank)&#10;&#10;    # Compute the percentile rank per index&#10;    percentile_rank_by_idx = {}&#10;    for idx, ranks in rank_lists.items():&#10;        if ranks:&#10;            rank_threshold = int(np.percentile(ranks, 100 * p, interpolation='higher'))&#10;            percentile_rank_by_idx[idx] = rank_threshold&#10;        else:&#10;            percentile_rank_by_idx[idx] = -1  # or np.inf / None if you prefer&#10;&#10;    return percentile_rank_by_idx&#10;&#10;def compute_percentile_radius_by_node(dataset, percentile_ranks):&#10;    &quot;&quot;&quot;&#10;    For each node v and each traversable index, return the distance from v to its&#10;    percentile-determined rank-th nearest neighbor.&#10;&#10;    Args:&#10;        dataset: np.ndarray of shape (n, d)&#10;        percentile_ranks: dict[int, int] — for each traversable index, the desired rank&#10;&#10;    Returns:&#10;        percentile_radii_by_node: dict[int, dict[int, float]]&#10;            Maps each node v to a dictionary mapping traversable idx → distance to rank-th NN&#10;    &quot;&quot;&quot;&#10;    n = len(dataset)&#10;    percentile_radii_by_node = defaultdict(dict)&#10;&#10;    for v in range(n):&#10;        # Precompute distances from v to all others, sorted&#10;        dists = [&#10;            (u, sq_Euclidean_d(dataset[v],dataset[u]))&#10;            for u in range(n) if u != v&#10;        ]&#10;        dists.sort(key=lambda x: x[1])&#10;        dist_list = [dist for _, dist in dists]&#10;&#10;        for idx, rank in percentile_ranks.items():&#10;            if rank &lt; len(dist_list):&#10;                percentile_radii_by_node[v][idx] = dist_list[rank]&#10;            else:&#10;                percentile_radii_by_node[v][idx] = float('inf')  # or np.nan&#10;&#10;    return percentile_radii_by_node&#10;&#10;def construction_phase(dataset, empirical=False, hnsw_M=32, ef_search=1):&#10;    &quot;&quot;&quot;&#10;    Constructs FAISS HNSW graph and ball-traversable graph.&#10;&#10;    Args:&#10;        dataset: np.ndarray of shape (n, d)&#10;        hnsw_M: int, max connections per node for HNSW&#10;        ef_search: int, efSearch parameter during query&#10;&#10;    Returns:&#10;        index: FAISS HNSW index&#10;        graph: dict[int, List[int]], ball-traversable graph&#10;        traversable_radii_by_node: dict[int, List[float]], radius levels used during construction&#10;    &quot;&quot;&quot;&#10;    d = dataset.shape[1]&#10;&#10;    # Build FAISS HNSW index (optional dependency)&#10;    try:&#10;        import faiss  # moved import here to avoid hard dependency at module import time&#10;    except Exception as _:&#10;        faiss = None&#10;&#10;    index = None&#10;    if faiss is not None:&#10;        index = faiss.IndexHNSWFlat(d, hnsw_M)&#10;        index.hnsw.efSearch = ef_search&#10;        index.hnsw.efConstruction = 100&#10;        index.add(dataset)&#10;&#10;    # Construct ball-traversable graph&#10;    graph, traversable_radii_by_node = build_ball_traversable_graph(dataset)&#10;&#10;    return index, graph, traversable_radii_by_node&#10;&#10;def create_percentile_radii_by_node(dataset, traversable_radii_by_node, k=5, p=0.95):&#10;    knns_by_node = compute_exact_knns(dataset, k=k)&#10;    empirical_geometry = compute_empirical_geometry(dataset, traversable_radii_by_node, knns_by_node)&#10;    percentile_ranks = compute_percentile_ranks(empirical_geometry, p=p)&#10;    percentile_radii_by_node = compute_percentile_radius_by_node(dataset, percentile_ranks)&#10;    return percentile_radii_by_node" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/allens_code/functions/query.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/allens_code/functions/query.py" />
              <option name="originalContent" value="from collections import deque&#10;import heapq&#10;import numpy as np&#10;from Exact_efSearch_functions.distance import sq_Euclidean_d&#10;&#10;def ceil_radius_to_safe_level(r, safe_radii, eps=1e-10):&#10;    &quot;&quot;&quot;&#10;    Return the smallest radius in safe_radii that is ≥ r,&#10;    and slightly inflate it to prevent tight comparison errors later.&#10;    &quot;&quot;&quot;&#10;    for radius in safe_radii:&#10;        if radius &gt;= r:&#10;            return radius * (1 + eps)&#10;    return float('inf')&#10;&#10;def bfs_within_ball_dynamic(graph, dataset, root, k, query,&#10;                            evaluated_set, traversable_radii_by_node,&#10;                            percentile_radii_by_node=None):&#10;    &quot;&quot;&quot;&#10;    Exact kNN search using dynamic radius and center-jumping strategy,&#10;    with distance-prioritized neighbor exploration.&#10;&#10;    Args:&#10;        graph: dict[int, List[int]]&#10;        dataset: np.ndarray of shape (n, d)&#10;        root: int — starting index (seed)&#10;        k: int — number of neighbors&#10;        query: np.ndarray of shape (d,)&#10;        evaluated_set: set[int] — tracks already evaluated points&#10;        traversable_radii_by_node: dict[int, List[Tuple[int, float]]] — list of (index, radius)&#10;        percentile_radii_by_node: dict[int, Dict[int, float]] or None — optional empirical radius per node&#10;&#10;    Returns:&#10;        visited: set[int]&#10;        knn_list: list of (distance, index)&#10;        jump_count: int&#10;    &quot;&quot;&quot;&#10;    jump_count = 0&#10;    visited = set()&#10;    visited.add(root)&#10;    expanded = set()&#10;&#10;    # Priority queue stores (distance, node)&#10;    queue = [(0.0, root)]&#10;&#10;    knn_heap = []  # Max-heap of (-distance, index)&#10;    best_idx = root&#10;    best_dist = sq_Euclidean_d(query, dataset[root])&#10;    evaluated_set.add(root)&#10;    heapq.heappush(knn_heap, (-best_dist, root))&#10;&#10;    jump_to_best = False&#10;&#10;    current_empirical_radius = None&#10;    if percentile_radii_by_node is not None:&#10;        levels = percentile_radii_by_node[best_idx]&#10;        sorted_items = sorted(levels.items())  # (index, radius)&#10;        current_empirical_radius = float(&quot;inf&quot;)&#10;        for _, r in sorted_items:&#10;            if r &gt;= best_dist:&#10;                current_empirical_radius = r&#10;                break&#10;&#10;    while queue:&#10;        if jump_to_best:&#10;            current = best_idx&#10;            jump_to_best = False&#10;            jump_count += 1&#10;            # Remove best_idx from queue if it’s in there (inefficient but rare)&#10;            queue = [(d, n) for d, n in queue if n != best_idx]&#10;            heapq.heapify(queue)&#10;        else:&#10;            _, current = heapq.heappop(queue)&#10;&#10;        expanded.add(current)&#10;        for neighbor in graph.get(current, []):&#10;            if neighbor in visited:&#10;                continue&#10;&#10;            # Determine radius&#10;            if percentile_radii_by_node is not None:&#10;                radius = current_empirical_radius&#10;            else:&#10;                kth_dist = -knn_heap[0][0] if len(knn_heap) == k else float('inf')&#10;                radius = (np.sqrt(best_dist) + np.sqrt(kth_dist))**2&#10;                safe_radii = [r for _, r in traversable_radii_by_node[best_idx]]&#10;                radius = ceil_radius_to_safe_level(radius, safe_radii)&#10;&#10;            dist_to_best = sq_Euclidean_d(dataset[best_idx], dataset[neighbor])&#10;&#10;            if dist_to_best &lt;= radius:&#10;                dist_to_q = sq_Euclidean_d(query, dataset[neighbor])&#10;                visited.add(neighbor)&#10;                heapq.heappush(queue, (dist_to_q, neighbor))&#10;&#10;                if neighbor not in evaluated_set:&#10;                    evaluated_set.add(neighbor)&#10;                    if len(knn_heap) &lt; k:&#10;                        heapq.heappush(knn_heap, (-dist_to_q, neighbor))&#10;                    elif dist_to_q &lt; -knn_heap[0][0]:&#10;                        heapq.heappushpop(knn_heap, (-dist_to_q, neighbor))&#10;&#10;                    if dist_to_q &lt; best_dist:&#10;                        best_dist = dist_to_q&#10;                        best_idx = neighbor&#10;                        jump_to_best = True&#10;&#10;                        # Update empirical radius if applicable&#10;                        if percentile_radii_by_node is not None:&#10;                            levels = percentile_radii_by_node[best_idx]&#10;                            sorted_items = sorted(levels.items())  # (index, radius)&#10;                            current_empirical_radius = float(&quot;inf&quot;)&#10;                            for _, r in sorted_items:&#10;                                if r &gt;= best_dist:&#10;                                    current_empirical_radius = r&#10;                                    break&#10;&#10;    knn_list = sorted([(-d, i) for d, i in knn_heap], key=lambda x: x[0])&#10;    return expanded, knn_list, jump_count&#10;&#10;def query_phase(query, index, dataset, graph, safe_radii_by_node, percentile_radii_by_node=None, k=5):&#10;    &quot;&quot;&quot;&#10;    Runs a query via FAISS HNSW (coarse) and exact BFS (fine).&#10;&#10;    Args:&#10;        query: np.ndarray of shape (d,)&#10;        index: FAISS index&#10;        dataset: np.ndarray&#10;        graph: dict[int, List[int]]&#10;        safe_radii_by_node: dict[int, List[(int,float)]]&#10;        k: int&#10;&#10;    Returns:&#10;        visited: set[int]&#10;        knn_list: list of (distance, index)&#10;        jump_count: int&#10;    &quot;&quot;&quot;&#10;    # Initial HNSW search&#10;    D, I = index.search(query.reshape(1, -1), k)&#10;    root = I[0][0]&#10;&#10;    visited, knn_list, jump_count = bfs_within_ball_dynamic(&#10;        graph=graph,&#10;        dataset=dataset,&#10;        root=root,&#10;        k=k,&#10;        query=query,&#10;        evaluated_set=set(),&#10;        traversable_radii_by_node=safe_radii_by_node,&#10;        percentile_radii_by_node=percentile_radii_by_node&#10;    )&#10;&#10;    return visited, knn_list, jump_count" />
              <option name="updatedContent" value="from collections import deque&#10;import heapq&#10;import numpy as np&#10;from .distance import sq_Euclidean_d&#10;&#10;def ceil_radius_to_safe_level(r, safe_radii, eps=1e-10):&#10;    &quot;&quot;&quot;&#10;    Return the smallest radius in safe_radii that is ≥ r,&#10;    and slightly inflate it to prevent tight comparison errors later.&#10;    &quot;&quot;&quot;&#10;    for radius in safe_radii:&#10;        if radius &gt;= r:&#10;            return radius * (1 + eps)&#10;    return float('inf')&#10;&#10;def bfs_within_ball_dynamic(graph, dataset, root, k, query,&#10;                            evaluated_set, traversable_radii_by_node,&#10;                            percentile_radii_by_node=None):&#10;    &quot;&quot;&quot;&#10;    Exact kNN search using dynamic radius and center-jumping strategy,&#10;    with distance-prioritized neighbor exploration.&#10;&#10;    Args:&#10;        graph: dict[int, List[int]]&#10;        dataset: np.ndarray of shape (n, d)&#10;        root: int — starting index (seed)&#10;        k: int — number of neighbors&#10;        query: np.ndarray of shape (d,)&#10;        evaluated_set: set[int] — tracks already evaluated points&#10;        traversable_radii_by_node: dict[int, List[Tuple[int, float]]] — list of (index, radius)&#10;        percentile_radii_by_node: dict[int, Dict[int, float]] or None — optional empirical radius per node&#10;&#10;    Returns:&#10;        visited: set[int]&#10;        knn_list: list of (distance, index)&#10;        jump_count: int&#10;    &quot;&quot;&quot;&#10;    jump_count = 0&#10;    visited = set()&#10;    visited.add(root)&#10;    expanded = set()&#10;&#10;    # Priority queue stores (distance, node)&#10;    queue = [(0.0, root)]&#10;&#10;    knn_heap = []  # Max-heap of (-distance, index)&#10;    best_idx = root&#10;    best_dist = sq_Euclidean_d(query, dataset[root])&#10;    evaluated_set.add(root)&#10;    heapq.heappush(knn_heap, (-best_dist, root))&#10;&#10;    jump_to_best = False&#10;&#10;    current_empirical_radius = None&#10;    if percentile_radii_by_node is not None:&#10;        levels = percentile_radii_by_node[best_idx]&#10;        sorted_items = sorted(levels.items())  # (index, radius)&#10;        current_empirical_radius = float(&quot;inf&quot;)&#10;        for _, r in sorted_items:&#10;            if r &gt;= best_dist:&#10;                current_empirical_radius = r&#10;                break&#10;&#10;    while queue:&#10;        if jump_to_best:&#10;            current = best_idx&#10;            jump_to_best = False&#10;            jump_count += 1&#10;            # Remove best_idx from queue if it’s in there (inefficient but rare)&#10;            queue = [(d, n) for d, n in queue if n != best_idx]&#10;            heapq.heapify(queue)&#10;        else:&#10;            _, current = heapq.heappop(queue)&#10;&#10;        expanded.add(current)&#10;        for neighbor in graph.get(current, []):&#10;            if neighbor in visited:&#10;                continue&#10;&#10;            # Determine radius&#10;            if percentile_radii_by_node is not None:&#10;                radius = current_empirical_radius&#10;            else:&#10;                kth_dist = -knn_heap[0][0] if len(knn_heap) == k else float('inf')&#10;                radius = (np.sqrt(best_dist) + np.sqrt(kth_dist))**2&#10;                safe_radii = [r for _, r in traversable_radii_by_node[best_idx]]&#10;                radius = ceil_radius_to_safe_level(radius, safe_radii)&#10;&#10;            dist_to_best = sq_Euclidean_d(dataset[best_idx], dataset[neighbor])&#10;&#10;            if dist_to_best &lt;= radius:&#10;                dist_to_q = sq_Euclidean_d(query, dataset[neighbor])&#10;                visited.add(neighbor)&#10;                heapq.heappush(queue, (dist_to_q, neighbor))&#10;&#10;                if neighbor not in evaluated_set:&#10;                    evaluated_set.add(neighbor)&#10;                    if len(knn_heap) &lt; k:&#10;                        heapq.heappush(knn_heap, (-dist_to_q, neighbor))&#10;                    elif dist_to_q &lt; -knn_heap[0][0]:&#10;                        heapq.heappushpop(knn_heap, (-dist_to_q, neighbor))&#10;&#10;                    if dist_to_q &lt; best_dist:&#10;                        best_dist = dist_to_q&#10;                        best_idx = neighbor&#10;                        jump_to_best = True&#10;&#10;                        # Update empirical radius if applicable&#10;                        if percentile_radii_by_node is not None:&#10;                            levels = percentile_radii_by_node[best_idx]&#10;                            sorted_items = sorted(levels.items())  # (index, radius)&#10;                            current_empirical_radius = float(&quot;inf&quot;)&#10;                            for _, r in sorted_items:&#10;                                if r &gt;= best_dist:&#10;                                    current_empirical_radius = r&#10;                                    break&#10;&#10;    knn_list = sorted([(-d, i) for d, i in knn_heap], key=lambda x: x[0])&#10;    return expanded, knn_list, jump_count&#10;&#10;def query_phase(query, index, dataset, graph, safe_radii_by_node, percentile_radii_by_node=None, k=5):&#10;    &quot;&quot;&quot;&#10;    Runs a query via FAISS HNSW (coarse) and exact BFS (fine).&#10;&#10;    Args:&#10;        query: np.ndarray of shape (d,)&#10;        index: FAISS index&#10;        dataset: np.ndarray&#10;        graph: dict[int, List[int]]&#10;        safe_radii_by_node: dict[int, List[(int,float)]]&#10;        k: int&#10;&#10;    Returns:&#10;        visited: set[int]&#10;        knn_list: list of (distance, index)&#10;        jump_count: int&#10;    &quot;&quot;&quot;&#10;    # Initial HNSW search&#10;    D, I = index.search(query.reshape(1, -1), k)&#10;    root = I[0][0]&#10;&#10;    visited, knn_list, jump_count = bfs_within_ball_dynamic(&#10;        graph=graph,&#10;        dataset=dataset,&#10;        root=root,&#10;        k=k,&#10;        query=query,&#10;        evaluated_set=set(),&#10;        traversable_radii_by_node=safe_radii_by_node,&#10;        percentile_radii_by_node=percentile_radii_by_node&#10;    )&#10;&#10;    return visited, knn_list, jump_count" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/configs/ball_prune_small.yaml">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/configs/ball_prune_small.yaml" />
              <option name="updatedContent" value="# Ball-Prune small config (O(N^2) build; keep N small)&#10;outdir: results&#10;metric: l2&#10;warmup: 5&#10;data_dir: data&#10;&#10;algorithms:&#10;  - name: ball_prune&#10;&#10;# small dataset to keep build time reasonable&#10;# format: toy_{dist}_N{N}_D{D}_nq{nq}_seed{seed}&#10;datasets:&#10;  - toy_gaussian_N2000_D64_nq200_seed42&#10;&#10;k_values: [1, 10]&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/requirements.txt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/requirements.txt" />
              <option name="originalContent" value="numpy&gt;=1.21&#10;psutil&gt;=5.9&#10;matplotlib&gt;=3.5&#10;PyYAML&gt;=6.0&#10;pytest&gt;=7.0&#10;&#10;" />
              <option name="updatedContent" value="numpy&gt;=1.21&#10;psutil&gt;=5.9&#10;matplotlib&gt;=3.5&#10;PyYAML&gt;=6.0&#10;pytest&gt;=7.0&#10;Flask&gt;=2.2" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/webui/server.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/webui/server.py" />
              <option name="originalContent" value="import os&#10;import sys&#10;import json&#10;import threading&#10;import queue&#10;import subprocess&#10;from pathlib import Path&#10;from typing import Optional&#10;&#10;from flask import Flask, Response, request, send_from_directory, jsonify&#10;import yaml&#10;&#10;app = Flask(__name__, static_folder=str(Path(__file__).parent / &quot;static&quot;))&#10;&#10;# Shared state&#10;event_q: &quot;queue.Queue[str]&quot; = queue.Queue()&#10;proc_lock = threading.Lock()&#10;runner_thread: Optional[threading.Thread] = None&#10;running_proc: Optional[subprocess.Popen] = None&#10;progress = {&#10;    &quot;total_steps&quot;: 0,&#10;    &quot;seen_steps&quot;: 0,&#10;    &quot;current&quot;: {&#10;        &quot;algo&quot;: None,&#10;        &quot;dataset&quot;: None,&#10;        &quot;k&quot;: None,&#10;    },&#10;    &quot;config_path&quot;: None,&#10;    &quot;run_dir&quot;: None,&#10;    &quot;status&quot;: &quot;idle&quot;,  # idle | running | finished | error&#10;}&#10;&#10;&#10;def _project_root() -&gt; Path:&#10;    return Path(__file__).resolve().parents[1]&#10;&#10;&#10;def _compute_total_steps(cfg_path: Path) -&gt; int:&#10;    with open(cfg_path, &quot;r&quot;) as f:&#10;        cfg = yaml.safe_load(f)&#10;    algorithms = cfg.get(&quot;algorithms&quot;, [])&#10;    datasets = cfg.get(&quot;datasets&quot;, [])&#10;    k_values = cfg.get(&quot;k_values&quot;, [10])&#10;    # count only actual algorithm entries&#10;    algo_count = 0&#10;    for a in algorithms:&#10;        if isinstance(a, dict) and a.get(&quot;name&quot;):&#10;            algo_count += 1&#10;        elif isinstance(a, str) and a:&#10;            algo_count += 1&#10;    return max(1, len(datasets)) * max(1, algo_count) * max(1, len(k_values))&#10;&#10;&#10;def _enqueue_event(payload: dict):&#10;    try:&#10;        event_q.put_nowait(json.dumps(payload))&#10;    except Exception:&#10;        pass&#10;&#10;&#10;def _reader_thread(proc: subprocess.Popen):&#10;    global running_proc&#10;    try:&#10;        for raw in iter(proc.stdout.readline, &quot;&quot;):&#10;            if not raw:&#10;                break&#10;            line = raw.rstrip(&quot;\n&quot;)&#10;            # push raw log event&#10;            _enqueue_event({&quot;type&quot;: &quot;log&quot;, &quot;line&quot;: line})&#10;            # parse progress lines like: &quot;[+] algo @ dataset metric=... k=...&quot;&#10;            if line.startswith(&quot;[+]&quot;) and &quot;@&quot; in line and &quot;k=&quot; in line:&#10;                try:&#10;                    # Example: &quot;[+] ball_prune @ toy_gaussian... metric=l2 k=10&quot;&#10;                    body = line[4:]&#10;                    left, right = body.split(&quot; @ &quot;, 1)&#10;                    algo = left.strip()&#10;                    rest = right.strip()&#10;                    ds_part, k_part = rest.rsplit(&quot; k=&quot;, 1)&#10;                    dataset = ds_part.split(&quot; metric=&quot;)[0].strip()&#10;                    k_val = int(k_part.strip())&#10;                    progress[&quot;current&quot;] = {&quot;algo&quot;: algo, &quot;dataset&quot;: dataset, &quot;k&quot;: k_val}&#10;                    progress[&quot;seen_steps&quot;] += 1&#10;                    _enqueue_event({&#10;                        &quot;type&quot;: &quot;progress&quot;,&#10;                        &quot;seen&quot;: progress[&quot;seen_steps&quot;],&#10;                        &quot;total&quot;: progress[&quot;total_steps&quot;],&#10;                        &quot;current&quot;: progress[&quot;current&quot;],&#10;                    })&#10;                except Exception:&#10;                    pass&#10;        rc = proc.wait()&#10;        progress[&quot;status&quot;] = &quot;finished&quot; if rc == 0 &quot;error&quot;&#10;        _enqueue_event({&quot;type&quot;: &quot;status&quot;, &quot;status&quot;: progress[&quot;status&quot;], &quot;returncode&quot;: rc})&#10;    finally:&#10;        with proc_lock:&#10;            running_proc = None&#10;&#10;&#10;def _start_run(config_path: str):&#10;    global runner_thread, running_proc&#10;    with proc_lock:&#10;        if running_proc is not None:&#10;            raise RuntimeError(&quot;A run is already in progress&quot;)&#10;        cfg = Path(config_path)&#10;        if not cfg.is_absolute():&#10;            cfg = _project_root() / config_path&#10;        if not cfg.exists():&#10;            raise FileNotFoundError(f&quot;Config not found: {cfg}&quot;)&#10;&#10;        progress[&quot;config_path&quot;] = str(cfg)&#10;        progress[&quot;total_steps&quot;] = _compute_total_steps(cfg)&#10;        progress[&quot;seen_steps&quot;] = 0&#10;        progress[&quot;current&quot;] = {&quot;algo&quot;: None, &quot;dataset&quot;: None, &quot;k&quot;: None}&#10;        progress[&quot;status&quot;] = &quot;running&quot;&#10;&#10;        # сразу оповестим клиентов о старте&#10;        _enqueue_event({&#10;            &quot;type&quot;: &quot;status&quot;,&#10;            &quot;status&quot;: progress[&quot;status&quot;],&#10;            &quot;total&quot;: progress[&quot;total_steps&quot;],&#10;            &quot;seen&quot;: progress[&quot;seen_steps&quot;],&#10;            &quot;current&quot;: progress[&quot;current&quot;],&#10;            &quot;config_path&quot;: progress[&quot;config_path&quot;],&#10;        })&#10;&#10;        # launch bench.py as subprocess (unbuffered)&#10;        python = sys.executable&#10;        env = os.environ.copy()&#10;        env[&quot;PYTHONUNBUFFERED&quot;] = &quot;1&quot;&#10;        proc = subprocess.Popen(&#10;            [python, &quot;-u&quot;, &quot;bench.py&quot;, &quot;--config&quot;, str(cfg)],&#10;            cwd=str(_project_root()),&#10;            stdout=subprocess.PIPE,&#10;            stderr=subprocess.STDOUT,&#10;            text=True,&#10;            bufsize=1,&#10;            env=env,&#10;        )&#10;        running_proc = proc&#10;        runner_thread = threading.Thread(target=_reader_thread, args=(proc,), daemon=True)&#10;        runner_thread.start()&#10;&#10;&#10;@app.route(&quot;/&quot;)&#10;def index():&#10;    return send_from_directory(app.static_folder, &quot;index.html&quot;)&#10;&#10;&#10;@app.route(&quot;/static/&lt;path:path&gt;&quot;)&#10;def static_files(path):&#10;    return send_from_directory(app.static_folder, path)&#10;&#10;&#10;@app.route(&quot;/run&quot;, methods=[&quot;POST&quot;])&#10;def run_bench():&#10;    try:&#10;        data = request.get_json(silent=True) or {}&#10;        config_path = data.get(&quot;config_path&quot;, &quot;configs/ball_prune_small.yaml&quot;)&#10;        _start_run(config_path)&#10;        return jsonify({&quot;ok&quot;: True, &quot;status&quot;: progress}), 202&#10;    except Exception as e:&#10;        return jsonify({&quot;ok&quot;: False, &quot;error&quot;: str(e)}), 400&#10;&#10;&#10;@app.route(&quot;/stream&quot;)&#10;def stream():&#10;    def event_stream():&#10;        # push initial status&#10;        _enqueue_event({&#10;            &quot;type&quot;: &quot;hello&quot;,&#10;            &quot;status&quot;: progress[&quot;status&quot;],&#10;            &quot;seen&quot;: progress[&quot;seen_steps&quot;],&#10;            &quot;total&quot;: progress[&quot;total_steps&quot;],&#10;            &quot;current&quot;: progress[&quot;current&quot;],&#10;            &quot;config_path&quot;: progress[&quot;config_path&quot;],&#10;        })&#10;        while True:&#10;            msg = event_q.get()&#10;            yield f&quot;data: {msg}\n\n&quot;&#10;    return Response(event_stream(), mimetype=&quot;text/event-stream&quot;)&#10;&#10;&#10;@app.route(&quot;/health&quot;)&#10;def health():&#10;    return jsonify({&quot;ok&quot;: True, &quot;status&quot;: progress.get(&quot;status&quot;, &quot;idle&quot;)})&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    # Run: python -m webui.server&#10;    print(&quot;[webui] Starting server on http://127.0.0.1:5000 …&quot;, flush=True)&#10;    app.run(host=&quot;127.0.0.1&quot;, port=5000, debug=False, threaded=True)&#10;" />
              <option name="updatedContent" value="import os&#10;import sys&#10;import json&#10;import threading&#10;import queue&#10;import subprocess&#10;from pathlib import Path&#10;from typing import Optional&#10;&#10;from flask import Flask, Response, request, send_from_directory, jsonify&#10;import yaml&#10;&#10;app = Flask(__name__, static_folder=str(Path(__file__).parent / &quot;static&quot;))&#10;&#10;# Shared state&#10;event_q: &quot;queue.Queue[str]&quot; = queue.Queue()&#10;proc_lock = threading.Lock()&#10;runner_thread: Optional[threading.Thread] = None&#10;running_proc: Optional[subprocess.Popen] = None&#10;progress = {&#10;    &quot;total_steps&quot;: 0,&#10;    &quot;seen_steps&quot;: 0,&#10;    &quot;current&quot;: {&#10;        &quot;algo&quot;: None,&#10;        &quot;dataset&quot;: None,&#10;        &quot;k&quot;: None,&#10;    },&#10;    &quot;config_path&quot;: None,&#10;    &quot;run_dir&quot;: None,&#10;    &quot;status&quot;: &quot;idle&quot;,  # idle | running | finished | error&#10;}&#10;&#10;&#10;def _project_root() -&gt; Path:&#10;    return Path(__file__).resolve().parents[1]&#10;&#10;&#10;def _compute_total_steps(cfg_path: Path) -&gt; int:&#10;    with open(cfg_path, &quot;r&quot;) as f:&#10;        cfg = yaml.safe_load(f)&#10;    algorithms = cfg.get(&quot;algorithms&quot;, [])&#10;    datasets = cfg.get(&quot;datasets&quot;, [])&#10;    k_values = cfg.get(&quot;k_values&quot;, [10])&#10;    # count only actual algorithm entries&#10;    algo_count = 0&#10;    for a in algorithms:&#10;        if isinstance(a, dict) and a.get(&quot;name&quot;):&#10;            algo_count += 1&#10;        elif isinstance(a, str) and a:&#10;            algo_count += 1&#10;    return max(1, len(datasets)) * max(1, algo_count) * max(1, len(k_values))&#10;&#10;&#10;def _enqueue_event(payload: dict):&#10;    try:&#10;        event_q.put_nowait(json.dumps(payload))&#10;    except Exception:&#10;        pass&#10;&#10;&#10;def _reader_thread(proc: subprocess.Popen):&#10;    global running_proc&#10;    try:&#10;        for raw in iter(proc.stdout.readline, &quot;&quot;):&#10;            if not raw:&#10;                break&#10;            line = raw.rstrip(&quot;\n&quot;)&#10;            # push raw log event&#10;            _enqueue_event({&quot;type&quot;: &quot;log&quot;, &quot;line&quot;: line})&#10;            # parse progress lines like: &quot;[+] algo @ dataset metric=... k=...&quot;&#10;            if line.startswith(&quot;[+]&quot;) and &quot;@&quot; in line and &quot;k=&quot; in line:&#10;                try:&#10;                    # Example: &quot;[+] ball_prune @ toy_gaussian... metric=l2 k=10&quot;&#10;                    body = line[4:]&#10;                    left, right = body.split(&quot; @ &quot;, 1)&#10;                    algo = left.strip()&#10;                    rest = right.strip()&#10;                    ds_part, k_part = rest.rsplit(&quot; k=&quot;, 1)&#10;                    dataset = ds_part.split(&quot; metric=&quot;)[0].strip()&#10;                    k_val = int(k_part.strip())&#10;                    progress[&quot;current&quot;] = {&quot;algo&quot;: algo, &quot;dataset&quot;: dataset, &quot;k&quot;: k_val}&#10;                    progress[&quot;seen_steps&quot;] += 1&#10;                    _enqueue_event({&#10;                        &quot;type&quot;: &quot;progress&quot;,&#10;                        &quot;seen&quot;: progress[&quot;seen_steps&quot;],&#10;                        &quot;total&quot;: progress[&quot;total_steps&quot;],&#10;                        &quot;current&quot;: progress[&quot;current&quot;],&#10;                    })&#10;                except Exception:&#10;                    pass&#10;        rc = proc.wait()&#10;        progress[&quot;status&quot;] = &quot;finished&quot; if rc == 0 else &quot;error&quot;&#10;        _enqueue_event({&quot;type&quot;: &quot;status&quot;, &quot;status&quot;: progress[&quot;status&quot;], &quot;returncode&quot;: rc})&#10;    finally:&#10;        with proc_lock:&#10;            running_proc = None&#10;&#10;&#10;def _start_run(config_path: str):&#10;    global runner_thread, running_proc&#10;    with proc_lock:&#10;        if running_proc is not None:&#10;            raise RuntimeError(&quot;A run is already in progress&quot;)&#10;        cfg = Path(config_path)&#10;        if not cfg.is_absolute():&#10;            cfg = _project_root() / config_path&#10;        if not cfg.exists():&#10;            raise FileNotFoundError(f&quot;Config not found: {cfg}&quot;)&#10;&#10;        progress[&quot;config_path&quot;] = str(cfg)&#10;        progress[&quot;total_steps&quot;] = _compute_total_steps(cfg)&#10;        progress[&quot;seen_steps&quot;] = 0&#10;        progress[&quot;current&quot;] = {&quot;algo&quot;: None, &quot;dataset&quot;: None, &quot;k&quot;: None}&#10;        progress[&quot;status&quot;] = &quot;running&quot;&#10;&#10;        # сразу оповестим клиентов о старте&#10;        _enqueue_event({&#10;            &quot;type&quot;: &quot;status&quot;,&#10;            &quot;status&quot;: progress[&quot;status&quot;],&#10;            &quot;total&quot;: progress[&quot;total_steps&quot;],&#10;            &quot;seen&quot;: progress[&quot;seen_steps&quot;],&#10;            &quot;current&quot;: progress[&quot;current&quot;],&#10;            &quot;config_path&quot;: progress[&quot;config_path&quot;],&#10;        })&#10;&#10;        # launch bench.py as subprocess (unbuffered)&#10;        python = sys.executable&#10;        env = os.environ.copy()&#10;        env[&quot;PYTHONUNBUFFERED&quot;] = &quot;1&quot;&#10;        proc = subprocess.Popen(&#10;            [python, &quot;-u&quot;, &quot;bench.py&quot;, &quot;--config&quot;, str(cfg)],&#10;            cwd=str(_project_root()),&#10;            stdout=subprocess.PIPE,&#10;            stderr=subprocess.STDOUT,&#10;            text=True,&#10;            bufsize=1,&#10;            env=env,&#10;        )&#10;        running_proc = proc&#10;        runner_thread = threading.Thread(target=_reader_thread, args=(proc,), daemon=True)&#10;        runner_thread.start()&#10;&#10;&#10;@app.route(&quot;/&quot;)&#10;def index():&#10;    return send_from_directory(app.static_folder, &quot;index.html&quot;)&#10;&#10;&#10;@app.route(&quot;/static/&lt;path:path&gt;&quot;)&#10;def static_files(path):&#10;    return send_from_directory(app.static_folder, path)&#10;&#10;&#10;@app.route(&quot;/run&quot;, methods=[&quot;POST&quot;])&#10;def run_bench():&#10;    try:&#10;        data = request.get_json(silent=True) or {}&#10;        config_path = data.get(&quot;config_path&quot;, &quot;configs/ball_prune_small.yaml&quot;)&#10;        _start_run(config_path)&#10;        return jsonify({&quot;ok&quot;: True, &quot;status&quot;: progress}), 202&#10;    except Exception as e:&#10;        return jsonify({&quot;ok&quot;: False, &quot;error&quot;: str(e)}), 400&#10;&#10;&#10;@app.route(&quot;/stream&quot;)&#10;def stream():&#10;    def event_stream():&#10;        # push initial status&#10;        _enqueue_event({&#10;            &quot;type&quot;: &quot;hello&quot;,&#10;            &quot;status&quot;: progress[&quot;status&quot;],&#10;            &quot;seen&quot;: progress[&quot;seen_steps&quot;],&#10;            &quot;total&quot;: progress[&quot;total_steps&quot;],&#10;            &quot;current&quot;: progress[&quot;current&quot;],&#10;            &quot;config_path&quot;: progress[&quot;config_path&quot;],&#10;        })&#10;        while True:&#10;            msg = event_q.get()&#10;            yield f&quot;data: {msg}\n\n&quot;&#10;    return Response(event_stream(), mimetype=&quot;text/event-stream&quot;)&#10;&#10;&#10;@app.route(&quot;/health&quot;)&#10;def health():&#10;    return jsonify({&quot;ok&quot;: True, &quot;status&quot;: progress.get(&quot;status&quot;, &quot;idle&quot;)})&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    # Run: python -m webui.server&#10;    print(&quot;[webui] Starting server on http://127.0.0.1:5000 …&quot;, flush=True)&#10;    app.run(host=&quot;127.0.0.1&quot;, port=5000, debug=False, threaded=True)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/webui/static/index.html">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/webui/static/index.html" />
              <option name="updatedContent" value="&lt;!doctype html&gt;&#10;&lt;html lang=&quot;ru&quot;&gt;&#10;&lt;head&gt;&#10;  &lt;meta charset=&quot;utf-8&quot; /&gt;&#10;  &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot; /&gt;&#10;  &lt;title&gt;KNN Bench — Мини UI&lt;/title&gt;&#10;  &lt;style&gt;&#10;    body { font-family: -apple-system, system-ui, Segoe UI, Roboto, sans-serif; margin: 20px; }&#10;    .row { margin-bottom: 12px; }&#10;    .btn { padding: 8px 12px; background:#0b5fff; color:#fff; border:0; border-radius:6px; cursor:pointer; }&#10;    .btn:disabled { background:#8aa8ff; cursor:not-allowed; }&#10;    .progress { width: 100%; height: 16px; background:#eee; border-radius:8px; overflow:hidden; }&#10;    .bar { height: 100%; background:#0b5fff; width:0%; transition: width .2s; }&#10;    .mono { font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; white-space: pre-wrap; }&#10;    #log { height: 300px; overflow: auto; border:1px solid #ddd; padding:8px; border-radius:6px; background:#fafafa; }&#10;    label { display:inline-block; width: 140px; color:#555; }&#10;    input[type=&quot;text&quot;] { width: 420px; padding:6px 8px; }&#10;  &lt;/style&gt;&#10;&lt;/head&gt;&#10;&lt;body&gt;&#10;  &lt;h2&gt;KNN Bench — Минимальный прогресс&lt;/h2&gt;&#10;&#10;  &lt;div class=&quot;row&quot;&gt;&#10;    &lt;label&gt;Config:&lt;/label&gt;&#10;    &lt;input id=&quot;cfg&quot; type=&quot;text&quot; value=&quot;configs/ball_prune_small.yaml&quot; /&gt;&#10;    &lt;button id=&quot;run&quot; class=&quot;btn&quot;&gt;Запустить&lt;/button&gt;&#10;  &lt;/div&gt;&#10;&#10;  &lt;div class=&quot;row&quot;&gt;&#10;    &lt;label&gt;Статус:&lt;/label&gt;&#10;    &lt;span id=&quot;status&quot;&gt;idle&lt;/span&gt;&#10;  &lt;/div&gt;&#10;&#10;  &lt;div class=&quot;row&quot;&gt;&#10;    &lt;label&gt;Текущий шаг:&lt;/label&gt;&#10;    &lt;span id=&quot;current&quot;&gt;—&lt;/span&gt;&#10;  &lt;/div&gt;&#10;&#10;  &lt;div class=&quot;row&quot;&gt;&#10;    &lt;div class=&quot;progress&quot;&gt;&lt;div id=&quot;bar&quot; class=&quot;bar&quot;&gt;&lt;/div&gt;&lt;/div&gt;&#10;    &lt;div&gt;&lt;span id=&quot;seen&quot;&gt;0&lt;/span&gt;/&lt;span id=&quot;total&quot;&gt;0&lt;/span&gt;&lt;/div&gt;&#10;  &lt;/div&gt;&#10;&#10;  &lt;div class=&quot;row&quot;&gt;&#10;    &lt;label&gt;Логи:&lt;/label&gt;&#10;  &lt;/div&gt;&#10;  &lt;div id=&quot;log&quot; class=&quot;mono&quot;&gt;&lt;/div&gt;&#10;&#10;  &lt;script&gt;&#10;    const runBtn = document.getElementById('run');&#10;    const cfgInput = document.getElementById('cfg');&#10;    const statusEl = document.getElementById('status');&#10;    const currentEl = document.getElementById('current');&#10;    const barEl = document.getElementById('bar');&#10;    const seenEl = document.getElementById('seen');&#10;    const totalEl = document.getElementById('total');&#10;    const logEl = document.getElementById('log');&#10;&#10;    function setProgress(seen, total) {&#10;      seenEl.textContent = seen;&#10;      totalEl.textContent = total;&#10;      const pct = total &gt; 0 ? Math.min(100, Math.round(seen * 100 / total)) : 0;&#10;      barEl.style.width = pct + '%';&#10;    }&#10;&#10;    function setCurrent(cur) {&#10;      const a = cur.algo || '—';&#10;      const d = cur.dataset || '—';&#10;      const k = (cur.k !== null &amp;&amp; cur.k !== undefined) ? cur.k : '—';&#10;      currentEl.textContent = `${a} @ ${d} k=${k}`;&#10;    }&#10;&#10;    function addLog(line) {&#10;      if (!line) return;&#10;      const atBottom = logEl.scrollTop + logEl.clientHeight &gt;= logEl.scrollHeight - 2;&#10;      logEl.textContent += line + '\n';&#10;      if (atBottom) logEl.scrollTop = logEl.scrollHeight;&#10;    }&#10;&#10;    // SSE stream&#10;    const es = new EventSource('/stream');&#10;    es.onmessage = (evt) =&gt; {&#10;      try {&#10;        const msg = JSON.parse(evt.data);&#10;        if (msg.type === 'hello') {&#10;          statusEl.textContent = msg.status;&#10;          setProgress(msg.seen || 0, msg.total || 0);&#10;          setCurrent(msg.current || {});&#10;          if (msg.status === 'running') runBtn.disabled = true;&#10;        } else if (msg.type === 'log') {&#10;          addLog(msg.line);&#10;        } else if (msg.type === 'progress') {&#10;          setProgress(msg.seen, msg.total);&#10;          setCurrent(msg.current || {});&#10;        } else if (msg.type === 'status') {&#10;          statusEl.textContent = msg.status;&#10;          runBtn.disabled = (msg.status === 'running');&#10;        }&#10;      } catch (_) { /* noop */ }&#10;    };&#10;&#10;    runBtn.onclick = async () =&gt; {&#10;      runBtn.disabled = true;&#10;      statusEl.textContent = 'running';&#10;      setProgress(0, 0);&#10;      setCurrent({});&#10;      logEl.textContent = '';&#10;      try {&#10;        const res = await fetch('/run', {&#10;          method: 'POST',&#10;          headers: { 'Content-Type': 'application/json' },&#10;          body: JSON.stringify({ config_path: cfgInput.value.trim() })&#10;        });&#10;        const data = await res.json();&#10;        if (!data.ok) {&#10;          addLog('Ошибка запуска: ' + (data.error || 'unknown'));&#10;          statusEl.textContent = 'error';&#10;          runBtn.disabled = false;&#10;        } else {&#10;          // totals may be known now&#10;          if (data.status) {&#10;            setProgress(data.status.seen || 0, data.status.total_steps || 0);&#10;          }&#10;        }&#10;      } catch (e) {&#10;        addLog('Исключение: ' + e);&#10;        statusEl.textContent = 'error';&#10;        runBtn.disabled = false;&#10;      }&#10;    };&#10;  &lt;/script&gt;&#10;&lt;/body&gt;&#10;&lt;/html&gt;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>